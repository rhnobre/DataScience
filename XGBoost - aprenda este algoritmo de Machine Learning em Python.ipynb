{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "XGBoost - aprenda este algoritmo de Machine Learning em Python.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhnobre/DataScience/blob/main/XGBoost%20-%20aprenda%20este%20algoritmo%20de%20Machine%20Learning%20em%20Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8X5yLPd_9IZ"
      },
      "source": [
        "# O Que é o Algoritmo XGBoost?\n",
        "\n",
        "---\n",
        "\n",
        "XGBoost é um dos algoritmos mais utilizados por cientistas de dados, apresentando resultados superiores principalmente em problemas de previsão envolvendo dados estruturados/tabulares.\n",
        "\n",
        "Dados tabulares são aquele tipo de estrutura usado pelo Pandas, os conhecidos DataFrames. Por suas características, consegue lidar eficientemente (e com robustez) com uma grande variedade de tipos diferentes de dados.\n",
        "\n",
        "Se você está lidando com problemas de regressão, pontuação ou classificação, definitivamente você precisa aprender a usar o XGBoost.\n",
        "\n",
        "Neste artigo, vou falar mais sobre esse algoritmo de *Machine Learning* que vem dominando cada vez mais as competições do [Kaggle](http://www.kaggle.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnD95QNh_9It"
      },
      "source": [
        "## Uma introdução ao XGBoost\n",
        "\n",
        "O nome XGBoost vem de *e**X**treme **G**radient **Boost**ing*, e representa uma categoria de algoritmo baseada em *Decision Trees* (árvores de decisão) com **Gradient Boosting** (aumento de gradiente).\n",
        "\n",
        "Aumento de gradiente significa que o algoritmo usa o algoritmmo *Gradient Descent* para minimizar a perda (*loss*) enquanto novos modelos vão sendo adicionado.\n",
        "\n",
        "Extremamente flexível - uma vez é possui um grande número de hiperparâmetros passíveis de aperfeiçoamento -, você consegue ajustar adequadamente o XGBoost para o cenário do seu problema, seja ele qual for.\n",
        "\n",
        "### Árvores de Decisão e *Gradient Boosting*\n",
        "\n",
        "Árvores de Decisão são métodos onde existe uma função que recebe um vetor de valores (de atributos) como entrada e retorna uma decisão (de saída).\n",
        "\n",
        "Para uma árvore de decisão chegar no valor de saída, executa uma série de etapas, ou testes, criando várias ramificações ao longo do processo.\n",
        "\n",
        "Cada nó dessa árvore representa uma decisão única. Quanto mais vezes um atributo for usado para as tomadas de decisão, maior será sua importância relativa no modelo.\n",
        "\n",
        "### *Gradient Boosting*\n",
        "\n",
        "*Gradient Boosting* é uma técnica relativamente recente, e que se mostrou muito poderosa.\n",
        "\n",
        "Tamanho é o seu potencial, que algoritmos baseados nessa técnica têm ganhando cada vez mais destaque em projetos de Data Science e competições do Kaggle.\n",
        "\n",
        "O princípio do *Gradient Boosting* é a capacidade de combinar resultados de muitos classificadores \"fracos\", tipicamente árvores de decisão, que se combinam para formar algo parecido com um \"comitê forte de decisão\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LwckQkN_9Iw"
      },
      "source": [
        "## Implementando XGBoost com Python\n",
        "\n",
        "Para mostrar na prática como se implementa o XGBoost, vou usar a API do Kaggle para baixar o *dataset* [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).\n",
        "\n",
        "Se você não conhece a [API Kaggle](https://github.com/Kaggle/kaggle-api) ou não quer usar ela, não tem problema! É só baixar o arquivo *zip* diretamente do link acima.\n",
        "\n",
        "Como a ideia é apenas mostrar a implementação da técnica, nem irei baixar todo o conjunto de dados, apenas um único arquivo: **train.csv**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTY7J3NJ_9Ix"
      },
      "source": [
        "!mkdir -p data\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques -f train.csv -p data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgwY3KiL_9Iz"
      },
      "source": [
        "### Importando e preparando os dados para o Pandas\n",
        "\n",
        "Após importar o pacote Pandas, vou importar aquele arquivo csv para dentro de um DataFrame.\n",
        "\n",
        "Para você entender o *dataset*, vou listar as 5 primeiras linhas de entrada do modelo. Recomendo que você baixe o *notebook* na tua máquina e faça o mesmo.\n",
        "\n",
        "Se você estiver executando diretamente na sua máquina, pode ser que você não tenha instalado o pacote ```xgboost```. Nesse caso, você pode instalar pela linha de comando:\n",
        "\n",
        "``` pip install xgboost```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nzq3ojPp_9I1",
        "outputId": "44c826e4-a49b-4140-b628-75b64e3f475a"
      },
      "source": [
        "# importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# importar train.csv em DataFrame\n",
        "df = pd.read_csv('data/train.csv')\n",
        "\n",
        "# visualizar as 5 primeiras entradas\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLOXuOP1_9I7"
      },
      "source": [
        "Neste *post* nós não vamos fazer uma análise aprofundada. O objetivo é que você aprenda a implementar o XGBoost nos seus modelos.\n",
        "\n",
        "Por isso, já dei uma olhada prévia no modelo e identifiquei que nossa variável alvo é a coluna ```SalePrice```. Também já verifiquei que não existem valores nulos na mesma.\n",
        "\n",
        "Para não termos que trabalhar as variáveis categóricas aqui, vou eliminar todas as colunas do tipo ```object``` e ficar apenas com as variáveis numéricas.\n",
        "\n",
        "Na sequência, vou separar entre o DataFrame entre as variáveis X e y e dividir o *dataset* entre conjuntos de treino e teste.\n",
        "\n",
        "Por último, vou usar a classe ```SimpleImputer()``` para lidar rapidamente com os valores ausentes do *dataset*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWhhPu8y_9I8"
      },
      "source": [
        "# separar entre as variáveis X e y\n",
        "y = df['SalePrice']\n",
        "X = df.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
        "\n",
        "# dividir entre conjuntos de treino e teste\n",
        "train_X, test_X, train_y, test_y = train_test_split(X.values, y.values, test_size=0.2)\n",
        "\n",
        "# lidar com os valores ausentes\n",
        "df_imputer = SimpleImputer()\n",
        "train_X = df_imputer.fit_transform(train_X)\n",
        "test_X = df_imputer.transform(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFA3yFYS_9I9"
      },
      "source": [
        "### Implementando um modelo de XGBoost com Python\n",
        "\n",
        "Com os nossos dados já preparados, agora é a hora de construir um modelo de *Machine Learning* XGBoost.\n",
        "\n",
        "Seguindo o mesmo padrão daquilo que você já está acostumado a fazer com o ```sklearn```, depois de instanciar ```XGBRegressor()``` basta executar o método ```fit()```, passando o *dataset* de treino como argumento.\n",
        "\n",
        "Na sequência, vamos realizar as previsões e calcular o erro médio absoluto para ver o desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur_Ofqr3_9I-",
        "outputId": "9844f6cd-db37-4722-f98e-86d940ec606f"
      },
      "source": [
        "# instanciar o modelo XGBoost\n",
        "model = XGBRegressor()\n",
        "\n",
        "# chamar o fit para o modelo\n",
        "model.fit(train_X, train_y, verbose=False)\n",
        "\n",
        "# fazer previsões em cima do dataset de teste\n",
        "predictions = model.predict(test_X)\n",
        "\n",
        "print(\"Erro Médio Absoluto: {:.2f}\".format(mean_absolute_error(predictions, test_y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05:08:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Erro Médio Absoluto: 15972.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoXhlUiD_9JA"
      },
      "source": [
        "Pronto. Construir um modelo é relativamente rápido comparado às outras etapas de um projeto.\n",
        "\n",
        "Entretanto, tem um passo a mais que faz muita diferença nos seus resultados usando esse algoritmo.\n",
        "\n",
        "### Parameter Tunning: ajustando parâmetros do XGBoost\n",
        "\n",
        "\n",
        "De maneira simples e direta, você viu na etapa anterior como construir um modelo XGBoost. Mas será que é tão simples assim conseguir aqueles resultados incríveis assim nas competições do Kaggle?\n",
        "\n",
        "Com certeza não! Se fosse assim, qualquer pessoa poderia estar no topo do *ranking*.\n",
        "\n",
        "O primeiro ponto que eu queria ressaltar é que não fizemos nenhuma análise aprofundada durante a etapa exploratória dos nossos dados - a fase mais importante de qualquer projeto de Data Science.\n",
        "\n",
        "O segundo ponto é que o XGBoost é extremamente robusto e poderoso, mas tem um grande número de parâmetros para serem ajustados ao problema.\n",
        "\n",
        "Para ajustar esses parâmetros, não tem escapatória. Você tem que entender a teoria por trás do XGBoost, seus conceitos matemáticos e estatísticos.\n",
        "\n",
        "##  Evoluindo com a prática\n",
        "\n",
        "Não existem atalhos em Data Science. Você tem que criar e participar do máximo de projetos que puder. \n",
        "\n",
        "Não seja uma pessoa que primeiro estuda tudo do assunto para no final começar a escrever códigos.\n",
        "\n",
        "Muita coisa você vai pegando com a experiência, então minha recomendação é:\n",
        "\n",
        "* Começe na prática, replicando métodos e *notebooks* dos outros;\n",
        "* Aprenda a teoria conforme for evoluindo, de acordo com a necessidade\n",
        "\n"
      ]
    }
  ]
}